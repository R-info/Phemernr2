{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 768)\n",
      "(1450, 768)\n",
      "(648, 768)\n",
      "(4327,)\n",
      "(1450,)\n",
      "(648,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.448\n",
      "Saving after new best accuracy : 87.586\n",
      "Saving after new best accuracy : 87.655\n",
      "-- Epoch 50, Train Loss : 0.27045538555830717, Test Loss : 0.5162160992622375\n",
      "-- Epoch 100, Train Loss : 0.266992655582726, Test Loss : 0.509584903717041\n",
      "-- Epoch 150, Train Loss : 0.24271681811660528, Test Loss : 0.5206195712089539\n",
      "-- Epoch 200, Train Loss : 0.24105239752680063, Test Loss : 0.5241748690605164\n",
      "-- Epoch 250, Train Loss : 0.25774857634678483, Test Loss : 0.5014100074768066\n",
      "-- Epoch 300, Train Loss : 0.2588681299239397, Test Loss : 0.5054604411125183\n",
      "-- Epoch 350, Train Loss : 0.23121421737596393, Test Loss : 0.5245590806007385\n",
      "-- Epoch 400, Train Loss : 0.24681492475792766, Test Loss : 0.5014168620109558\n",
      "-- Epoch 450, Train Loss : 0.2549852295778692, Test Loss : 0.49758270382881165\n",
      "-- Epoch 500, Train Loss : 0.24362079426646233, Test Loss : 0.5109779238700867\n",
      "-- Epoch 550, Train Loss : 0.24811046989634633, Test Loss : 0.5130672454833984\n",
      "-- Epoch 600, Train Loss : 0.24376464635133743, Test Loss : 0.5181182622909546\n",
      "-- Epoch 650, Train Loss : 0.23606838937848806, Test Loss : 0.5327325463294983\n",
      "-- Epoch 700, Train Loss : 0.23963629081845284, Test Loss : 0.5307613611221313\n",
      "-- Epoch 750, Train Loss : 0.2352692261338234, Test Loss : 0.5455214977264404\n",
      "-- Epoch 800, Train Loss : 0.24463696917518973, Test Loss : 0.5228792428970337\n",
      "-- Epoch 850, Train Loss : 0.22097077034413815, Test Loss : 0.5594768524169922\n",
      "-- Epoch 900, Train Loss : 0.23875691974535584, Test Loss : 0.5289707183837891\n",
      "Saving after new best accuracy : 87.793\n",
      "-- Epoch 950, Train Loss : 0.22983612585812807, Test Loss : 0.5384994745254517\n",
      "-- Epoch 1000, Train Loss : 0.22124790027737617, Test Loss : 0.548296332359314\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 96.83 seconds\n",
      "loading model from ../../data/models/Phemernr2-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1450])\n",
      "1450 vs 1450\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 86.278 %\n",
      "- Recall : 81.528 %\n",
      "- F1 : 0.83836\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 88.671 %\n",
      "- Recall : 91.77 %\n",
      "- F1 : 0.90194\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.793 %\n",
      "- Precision : 87.475 %\n",
      "- Recall : 86.649 %\n",
      "- F1 : 0.8706\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Validation, 87.793, 87.475, 86.649, 0.8706, 86.278, 81.528, 0.83836, 88.671, 91.77, 0.90194, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([648])\n",
      "648 vs 648\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 83.26 %\n",
      "- Recall : 78.423 %\n",
      "- F1 : 0.80769\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 87.648 %\n",
      "- Recall : 90.663 %\n",
      "- F1 : 0.8913\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.111 %\n",
      "- Precision : 85.454 %\n",
      "- Recall : 84.543 %\n",
      "- F1 : 0.84996\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Test, 86.111, 85.454, 84.543, 0.84996, 83.26, 78.423, 0.80769, 87.648, 90.663, 0.8913, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
